{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "07_panel_data_mixed_logit",
      "provenance": [],
      "authorship_tag": "ABX9TyOehleR43bZtYLH2IrCmfXg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pmontman/tmp_choicemodels/blob/main/nb/WK_07_panel_data_mixed_logit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvR8vfvdKmFi"
      },
      "source": [
        "# Panel data and the Mixed logit model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4SZPNgSVVSG"
      },
      "source": [
        "We will introduce two topics\n",
        " * Panel Data\n",
        " * The mixed logit model\n",
        "\n",
        "Very briefly: Panel data are **data that involves repeated measures over time**. In the case of choice modelling, it means observing the decision makers on repeated decisions. The mixed logit model is another extension of the logit family that involves **random coefficients**, when we consider that the Betas vary among individuals and are randomly distributed among a population.\n",
        "\n",
        "First of all, these are two different ideas so they should not be confused.\n",
        "Confusion might appear because traditionally the mixed logit model is applied when we have panel data, so they often appear together.\n",
        "\n",
        "---\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQOR4mFkgwr7"
      },
      "source": [
        "#Panel data\n",
        "Panel data is an econometrics term that is also called repeated observations.\n",
        "Very often, we have a sample of individuals and we track their choices through time.\n",
        "\n",
        "Examples:\n",
        " * In the first lecture, we describe an example of tracking the purchases of coffee that households make in a supermarket over a period of one year (using barcode scanner). Households being the decision making 'individuals', we have data about the decisions (brand of coffe purchased) of each individual over time, and the individuals are identified (we have a variable that identifies which indidivual made the purchase).\n",
        "\n",
        " * We can track stock purchases in portfolio management: each day, each individual is faced with the choice among different stocks (each stock is an alternative), and the price of the stock (attributes) changes each day. (Example from Bierlare)\n",
        "\n",
        " * In a survey, we could ask the  participants to choose considering hypothetical choice situations, by changing the attributes of the alternatives. For example, we can ask participants about smartphones when changing screen sizes, cost, etc. in a marketing research survey. In this case, we would get repeated choices for each individual.\n",
        "\n",
        "\n",
        "\n",
        "While panel data can be often considered as a time series for each individual, it is a more general concept. For example, in a panel we could have a different number of observations for each individual (some individuals are not properly tracked through time) or the actual time dimension is not that relevant. A more general term is 'repeated measures' coming from Statistics.\n",
        "\n",
        " Finally, the respective term when we have data for the individuals at one point in time is **cross-sectional** data.\n",
        "\n",
        " ---\n",
        " ---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R88VV7crivLR"
      },
      "source": [
        "#Types of panel data\n",
        "When we have measurements over time, we can start talking about the effect of factors that changeove time. This can split the panel data into two broad categoies:\n",
        " * Static panels\n",
        " * Dynamic panels\n",
        "\n",
        "We introduce some new mathematical notation:\n",
        "\n",
        " $$U_{jit} = V_{jit} + \\varepsilon_{jit}$$\n",
        "\n",
        "with $j$ representing the alternative, $i$ the individual and $t$ the instant of time at which the decision is made. We can read this a the utility that the individual $i$ received from alternative $j$ at time $t$.\n",
        " As we have seen before, depending on what we assumen of the $\\varepsilon$s, we can reach different models.\n",
        " \n",
        "Remember, we often assume that the $\\varepsilon$s are independent across individuals and they follow the extreme value distribution, and then\n",
        "* If the $\\varepsilon$s are indepent across alternatives we would be talking about the logit, if the $\\varepsilon$s are dependent across alternatives we could be talking about the nested logit.\n",
        "\n",
        "* In the case of independence across time,  if the $\\varepsilon$s are independent over time we can be talking about static panels, if they are dependent we can be talking about dynamic panels. \n",
        "\n",
        "As we have mentioned before, a very imporant point, how we specify a model can change the static/dynamic nature, in the case of time **we can make a dynamic panel become static if we can capture the source of dependence over time.**\n",
        "\n",
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZNkVUHeiNQ6"
      },
      "source": [
        "# Panel data: Static panel\n",
        "\n",
        "When assume that the errors are for each individual are independent over time, a panel data reduces to the examples that we have seen before in other lectures, we treat observations of each individual 'as if' they were coming from different individuals and the modelling reduces to what we have been doing until now (we now have a term for these situations of one sample per individual, cross-sectional data).\n",
        "\n",
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RbQIoTqbaES"
      },
      "source": [
        "# Panel data: Dynamic panel\n",
        "\n",
        "When there is dependence over time, we can think of two general sources for this dependence.\n",
        "\n",
        " * Dependence of not only the present state, but on past states. In choice modelling, we can think of different effects:\n",
        "    * Choice fatigue\n",
        "    * Addiction / familiarity / habit\n",
        "    * Novelty seeking\n",
        "    * Learning effects: Know more information about a product when buying it, or through other means (user opinions that accumulate over time).\n",
        "    * Anticipation: For example, when there is a clear pattern of evolution of prices over time, individuals can consider it when making choices (buy a house in a trending area).\n",
        "\n",
        " * Effect of the individual: agent-effect or 'serial correlation'. Because we have repeated observations, it becomes more meaningful to talk about the effects that are related to each specific individual. This is because we can estimate it, as opposed to a cross-section which the estimation would not be reliable.\n",
        "\n",
        "Again, these two sources is just a way of thinking, depends on what sources of influence we can capture of the underlying process. For example, the size of the agent effect might be reduced if we can capture the variable that drives it. Imagine that gender is an important factor, and we are not capturing it, the we will see that the errors for each individual are correlated, the errors of each individual will be more similar compared to the sample (unless that individual randomly changes gender) .\n",
        "\n",
        "---\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sNPedTxp4Z1"
      },
      "source": [
        "# Capturing dynamics: Lagged variables\n",
        "\n",
        "We can try to capture the dynamics of a choice process in several way.\n",
        "A common way to capture the dynamics is to think that the utility depends on variables measured at other instants of time.\n",
        "\n",
        " For example, the decision of whether to buy a house can depend on the current value, but also on recent past values if a trend is identified. Plainly speaking, two house at the same current price, one of those has been increasing its price for 5 years, the other has been decreasing its price for 5 years, Which one would you buy?\n",
        "\n",
        " Another example we can consider: past choices a one of the variables, the past selection of smartphone brand can influence a current choice, for example if we buy a phone of a brand that generates familiarity / aversion to change.\n",
        "\n",
        " All these fall in to the umbrella term of 'Lagged variables'\n",
        "\n",
        "In mathematical notation, we start from the familiar specification of observed component of the utility as a linear combination of some varaibles.\n",
        " $$ V_{jit} = \\beta X_{jit} $$\n",
        " Notice the subindex $t$ represents the value of variables (attributes and characteristics) measured at the specific point it time t.\n",
        "\n",
        " We can introduce lagged variables in a very general way by adding another set of coefficients that  \n",
        "\n",
        " $$V_{jit} = \\beta X_{jit} + \\gamma X_{ji(t-1)}$$\n",
        "\n",
        " Of course, we might only select a few variables from the past, and we can introduce instants of time $(t-2), (t-3), ...$\n",
        "\n",
        " A particularly important lagged variable in choice modelling is past choices, which is quite special because it cannot be measured in the present, it is what we want to predict. Past choices can be introduced into the model as dummy (indicator for each) or in more compact form, for example a binary variable indicating whether it changed or not, the number of times that each was chose in the past and so on.\n",
        "\n",
        " **What we expect when introducing lagged variables is that the dependence across time is captured, and then we can treat the model as usual, as a static panel or cross-section.**\n",
        "\n",
        " ---\n",
        " ---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UVfP5kshrJNX"
      },
      "source": [
        "# Capturing dynamics: Agent effect\n",
        "\n",
        "A natural idea to consider is 'choice' heterogeneity, or that each individual has its own utility function.\n",
        "\n",
        "\n",
        "In panel data, because we have repeated observations, we can try to estimate effects of each individual, roughly speaking it would be like estimating a logit for each individual.\n",
        "\n",
        "The notation:\n",
        "\n",
        "$$ V_{jit} = \\beta X_{jit} + \\alpha_{ji} $$\n",
        "\n",
        "With the $\\alpha$ being the simplest form of agent effect, just a constant. Notice the subindices of the $\\alpha$, there is no reference to the instant of time. This means that utility has a common part to all individuals, and the individual specific part that remains consant through time.\n",
        "When we introduce the agent effect, we again expect that the effect thorugh time is captured and we can afterwards treach the model as if it was static / no dependence across time.\n",
        "\n",
        "\n",
        "Even though we can estimate the agent effects when we have repeated measures, we might still fall into small sample size problems, not enough repreated observations.\n",
        " * Fixed effects: The coefficients are fixed and we want to estimate them.\n",
        " * Random effects: We consider that the effect of the individuals are random coming from a specific probability distribution. This leads us to the mixed logit model. \n",
        "\n",
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNFN_kiXFSTL"
      },
      "source": [
        "# Limitations of agent effects\n",
        "\n",
        "  This seems very reasonable, but it has two problems:\n",
        " - 1) It requires a lot of data to estimate, since we have a set of coefficients per individual!\n",
        " - 2) What do we do when we want to predict the choices for individuals in a population?\n",
        "\n",
        " \n",
        "Therefore agent effects can be important, but are less general applicable than others parameters of the model. The are relevant when trying to accurately estimate **the other** parameters of the model. \n",
        "\n",
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xe4B1ntF8Vru"
      },
      "source": [
        "# Mixed logit\n",
        "\n",
        "The mixed logit comes from considering a logit model that has both fixed effects (the usual) and random effects (the one we will introduce here). Ther term comes from the more general term 'mixed model' or 'mixed-effects' model in Statistics.\n",
        "\n",
        "A fixed effects model is what we have been doing, the paremeters are fixed or deterministic all individuals in the population, and we want to estimate their values.\n",
        "\n",
        "$$V_{ijt} = \\beta X_{jit}$$\n",
        "\n",
        "A random effects model assumes that there is a beta for each individual\n",
        "\n",
        "$$V_{ijt} = \\beta'_i X_{jit}$$ and what we want to estimate for the $\\beta'$,but these are actually unkown and what we can do is **just estimate the distribution** of the $\\beta$s.\n",
        "For example, the mean and variance of the $\\beta$s assuming that they are normally distributed.\n",
        "\n",
        "---\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHdMWIJJ-QZm"
      },
      "source": [
        "# Mixed logit for estimating the agent effect\n",
        "\n",
        "The agent effect can be linked to both fixed and random effects model by considering dummy indicator variables (a variable for each individual) or individual specific 'constants'.\n",
        "\n",
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eF071xfgidaY"
      },
      "source": [
        "# Comparing fixed and random effects\n",
        "The advantage of the random effects model is that we can get a better estimation\n",
        "of the coefficients (the true population average) compared to the fixed effects. This of course assuming that we have correctly specified the distribution of the parameters.\n",
        "\n",
        "The difference becomes especially relevant in panel data, because we might have a different amount of observation for each individual, so we can capture the excessive influence of some individuals that might be overrepresented.\n",
        "\n",
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L391wlL2_L45"
      },
      "source": [
        "# Final words\n",
        "\n",
        "Panel data usal has larger sample sizes which allows us to try more advanced models,relative to cross-section, so there is always the tradeoff vs model complexity, try to capture as much effect as possible vs. new model methodologies such as agent effects or mixed models. In other words, we might treat panel data as cross sectional and try more complex models, with more variable transformations, or add more variables into the model.\n",
        "\n",
        "For example, just adding a constant agent effect if we have a sample size of 1000 individuals, we would be adding 1000 parameters to the model, so maybe we could be trying a 'static' model with more complex variable transformations. As always, it depends on the context and our interests. We could be interested in prediction, in which case we would go for the more complex model. Or we could be interested in estimating the values of some of the parameters in a simple model as best as possible (for example, insolate the effect of price in a linear model), in which case we could opt for the mixed logit approach.\n",
        "\n",
        "This discussion is becoming increasingly relevant in modern times, as we get more advanced tools, much more data and the focus from interpretation shifts towards prediction.\n",
        "\n",
        "---\n",
        "---"
      ]
    }
  ]
}
