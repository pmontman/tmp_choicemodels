{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "practice_final",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pmontman/tmp_choicemodels/blob/main/nb/tutorials/practice_final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rxbeRIOOkIRc"
      },
      "source": [
        "#Types of questions for the final exam\n",
        "\n",
        "We will see:\n",
        " * Nested logit\n",
        " * Ordered logit\n",
        " * Panel data and Mixed logit\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vb9SIunnASNB"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "# Preparing the environment\n",
        "*The preparation and dataset loading code is given to the students*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5zHGhgErHPd"
      },
      "source": [
        "!pip install biogeme"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1z0X9xZ8rChf"
      },
      "source": [
        "Load the packages, feel free to change the names."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "apVB-TMkrFnb"
      },
      "source": [
        "import pandas  as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import biogeme.database as db\n",
        "import biogeme.biogeme as bio\n",
        "import biogeme.models as models\n",
        "import biogeme.expressions as exp\n",
        "import biogeme.tools as tools\n",
        "import biogeme.distributions as dist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mgv0hV1YAieW"
      },
      "source": [
        "# Load the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1Ykn5Ytr7Rs"
      },
      "source": [
        "path = 'https://raw.githubusercontent.com/pmontman/pub-choicemodels/main/data/fishing.csv'\n",
        "data_pd = pd.read_csv(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY55r3Gesb3t"
      },
      "source": [
        "A simple look at the dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldkmnMhssemT"
      },
      "source": [
        "data_pd.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEJvXwpekbvd"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "# Auxiliary functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKyKA_dj-IVp"
      },
      "source": [
        "The first function takes the dictionary of utilities, a pandas dataframe, and the name of the variable that contains the variable with the results of the choice. It returns the biogeme object with the model and the estimated 'results' object (the one we get the values, likelihoods, etc.)\n",
        "We have added the dictionary with the utilities to the biogeme object, in case we use it later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OQ1ls2Bi_ot"
      },
      "source": [
        "def qbus_estimate_bgm(V, pd_df, tgtvar_name, modelname='bgmdef'):\n",
        " av_auto = V.copy()\n",
        " for key, value in av_auto.items():\n",
        "   av_auto[key] = 1\n",
        " bgm_db = db.Database(modelname + '_db', pd_df)\n",
        " globals().update(bgm_db.variables)\n",
        " logprob = models.loglogit (V , av_auto , bgm_db.variables[tgtvar_name] )\n",
        " bgm_model = bio.BIOGEME ( bgm_db, logprob )\n",
        " bgm_model.utility_dic = V.copy()\n",
        " return bgm_model, bgm_model.estimate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dM2f5-0w-_4b"
      },
      "source": [
        "The next function will calculate the predictions for a given biogeme object that was estimated with `qbus_estimate_bgm`. The output is the array with the choice probabilities. From the choice probabilities, this can be used to calculate accuracies, confusion matrices and the output of what-if scenarios."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4Iau_IHHCzc"
      },
      "source": [
        "def qbus_simulate_bgm(qbus_bgm_model, betas, pred_pd_df):\n",
        "  av_auto = None\n",
        "  targets = None\n",
        "  if hasattr(qbus_bgm_model, 'ord_probs'):\n",
        "    av_auto = qbus_bgm_model.ord_probs.copy()\n",
        "    targets = qbus_bgm_model.ord_probs.copy()\n",
        "  else:\n",
        "    av_auto = qbus_bgm_model.utility_dic.copy()\n",
        "    targets = qbus_bgm_model.utility_dic.copy()\n",
        "\n",
        "  for key, value in av_auto.items():\n",
        "    av_auto[key] = 1\n",
        "\n",
        "\n",
        "\n",
        "  for key, value in targets.items():\n",
        "    if hasattr(qbus_bgm_model, 'nest_tuple'):\n",
        "      targets[key] = models.nested(qbus_bgm_model.utility_dic, av_auto, qbus_bgm_model.nest_tuple, key)\n",
        "    else:\n",
        "      if hasattr(qbus_bgm_model, 'ord_probs'):\n",
        "       0\n",
        "       #targets[key] = qbus_bgm_model.ord_probs[key]\n",
        "      else:\n",
        "       targets[key] = models.logit(qbus_bgm_model.utility_dic, av_auto, key)\n",
        "\n",
        "  bgm_db = db.Database('simul', pred_pd_df)\n",
        "  globals().update(bgm_db.variables)\n",
        "  bgm_pred_model = bio.BIOGEME(bgm_db, targets)\n",
        "  simulatedValues = bgm_pred_model.simulate(betas)\n",
        "  return simulatedValues"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AnBLUPi-DjU7"
      },
      "source": [
        "The function `qbus_calc_accu_confusion` calculates the accuracies given the choice probability predictions a pandas dataset and the specification of the name that contains the actual choices in the input dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9l5cDGkzsfJ"
      },
      "source": [
        "def qbus_calc_accu_confusion(sim_probs, pd_df, choice_var):\n",
        "  which_max = sim_probs.idxmax(axis=1)\n",
        "  data = {'y_Actual':   pd_df[choice_var],\n",
        "          'y_Predicted': which_max\n",
        "        }\n",
        "\n",
        "  df = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
        "  confusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
        "  accu = np.mean(which_max == pd_df[choice_var])\n",
        "  return accu, confusion_matrix "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYfxQpYLDzgm"
      },
      "source": [
        "The next function calculates the likelihood ratio test having to write a bit less code that the default biogeme function. The arguments are the results objects of the two models to be compared. The first is the more complex and the second is the reference model (**the order is important!**). The third argument is the significance level for the test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GUNVxPmK3rF2"
      },
      "source": [
        "def qbus_likeli_ratio_test_bgm(results_complex, results_reference, signif_level):\n",
        "  return tools.likelihood_ratio_test( (results_complex.data.logLike, results_complex.data.nparam),\n",
        "                                     (results_reference.data.logLike, results_reference.data.nparam), signif_level)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b7TaMhCEZIZ"
      },
      "source": [
        "The next function just updates the globals so we can use it "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfHXGoLS1yHX"
      },
      "source": [
        "def qbus_update_globals_bgm(pd_df):\n",
        "   globals().update(db.Database('tmp_bg_bgm_for_glob', pd_df).variables)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buGCdfDc47M4"
      },
      "source": [
        "The next function calculates the nested logit version. Similar to the multinomial logit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QEo3d3kJo2BV"
      },
      "source": [
        "def qbus_estimate_nested_bgm(V, pd_df, nests,  tgtvar_name, modelname='bgmdef'):\n",
        " av_auto = V.copy()\n",
        " for key, value in av_auto.items():\n",
        "   av_auto[key] = 1\n",
        " bgm_db = db.Database(modelname + '_db', pd_df)\n",
        " globals().update(bgm_db.variables)\n",
        " logprobnest = models.lognested (V, av_auto , nests , bgm_db.variables[tgtvar_name] )\n",
        " #logprob = models.loglogit (V , av_auto , bgm_db.variables[tgtvar_name] )\n",
        " bgm_model = bio.BIOGEME ( bgm_db, logprobnest )\n",
        " bgm_model.utility_dic = V.copy()\n",
        " bgm_model.nest_tuple = nests\n",
        " return bgm_model, bgm_model.estimate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lvu4rY2z0lnG"
      },
      "source": [
        "The auxiliary function for the ordered logit. The use is slightly different from the basic multinomial logit!\n",
        "* The `V` argument is just the expression of a utility function, not the dictionary mapping alternative ids to the utility functions.\n",
        "* The argument `ord_alt_ids` is a list with the ids of the alternatives **in the order that we want to impose**.The parameter to know about.\n",
        "\n",
        "Then the rest of the arguments are used as usual `pd_df` the pandas dataframe, `tgt_varname` the name of the variable with the choices, and an optional `modelname`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cNy29oJjLtM"
      },
      "source": [
        "def qbus_estimate_ordered_bgm(V, ord_alt_ids, pd_df, tgtvar_name, modelname='ord_bgm'):\n",
        " bgm_db = db.Database(modelname + '_db', pd_df)\n",
        " globals().update(bgm_db.variables)\n",
        "\n",
        " taus_map = {ord_alt_ids[0]: exp.Beta('tau1', -1, None, None, 0) }\n",
        " i = 1\n",
        " for id in ord_alt_ids[1:-1]:\n",
        "  taus_map[id] = taus_map[ ord_alt_ids[i-1] ] + exp.Beta('delta_'+ str(i + 1), i, 0, None, 0)\n",
        "  i = i + 1\n",
        "\n",
        " alt_probs_map = {ord_alt_ids[0]: dist.logisticcdf( taus_map[ord_alt_ids[0] ] - V_ord) }\n",
        "\n",
        " i = 1\n",
        " for id in ord_alt_ids[1:-1]:\n",
        "  alt_probs_map[id] = dist.logisticcdf( taus_map[id] - V_ord) - dist.logisticcdf( taus_map[ ord_alt_ids[i-1] ] - V_ord)\n",
        "  i = i + 1\n",
        "\n",
        " alt_probs_map[ord_alt_ids[i] ] = 1 - dist.logisticcdf( taus_map[ord_alt_ids[i-1]] - V_ord)\n",
        "\n",
        " logprob = exp.log(exp.Elem(alt_probs_map, bgm_db.variables[tgtvar_name]))\n",
        "\n",
        " #logprob = models.loglogit (V , av_auto , bgm_db.variables[tgtvar_name] )\n",
        " bgm_model = bio.BIOGEME ( bgm_db, logprob )\n",
        " bgm_model.utility_dic = V\n",
        " bgm_model.ord_probs = alt_probs_map.copy()\n",
        " return bgm_model, bgm_model.estimate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApSvgeffCcRT"
      },
      "source": [
        "The mixed logit with panel data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2n-4SIpBCpCI"
      },
      "source": [
        "def qbus_estimate_mixed_bgm(V, pd_df, tgtvar_name, panelvar_name=None, n_draws=50, seed=1, modelname='bgmdef'):\n",
        " do_panel = not (panelvar_name==None)\n",
        "\n",
        " av_auto = V.copy()\n",
        " for key, value in av_auto.items():\n",
        "   av_auto[key] = 1\n",
        " bgm_db = db.Database(modelname + '_db', pd_df)\n",
        " if (do_panel):\n",
        "   bgm_db.panel(panelvar_name)\n",
        "\n",
        " globals().update(bgm_db.variables)\n",
        " #logprob = models.loglogit (V , av_auto , bgm_db.variables[tgtvar_name] )\n",
        " obsprob = models.logit(V, av_auto, CHOICE)\n",
        " if (do_panel):\n",
        "  condprobIndiv = exp.PanelLikelihoodTrajectory(obsprob)\n",
        " else:\n",
        "  condprobIndiv = obsprob\n",
        " logprob = exp.log(exp.MonteCarlo(condprobIndiv))\n",
        " bgm_model  = bio.BIOGEME(bgm_db,logprob,numberOfDraws=n_draws, seed=seed)\n",
        " bgm_model.utility_dic = V.copy()\n",
        " return bgm_model, bgm_model.estimate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ya_1zth9vEX1"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "# Estimating a baseline model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeRgbCnbG4aD"
      },
      "source": [
        "ASC_beach = exp.Beta ( 'ASC_beach' ,0, None , None ,0)\n",
        "ASC_pier = exp.Beta ( 'ASC_pier' ,0, None , None ,0)\n",
        "ASC_boat = exp.Beta ( 'ASC_boat' ,0, None , None ,0)\n",
        "ASC_charter = exp.Beta ( 'ASC_charter' ,0, None , None ,1)\n",
        "B_price = exp.Beta ( 'B_price' ,0, None , None ,0)\n",
        "B_catch = exp.Beta ( 'B_catch' ,0, None , None ,0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDPllyLIijIy"
      },
      "source": [
        "qbus_update_globals_bgm(data_pd)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HG_YkIVy2NbS"
      },
      "source": [
        "V_beach = ASC_beach + B_price*price_beach + B_catch*catch_beach\n",
        "V_pier = ASC_pier + B_price*price_pier + B_catch*catch_pier\n",
        "V_boat = ASC_boat + B_price*price_boat + B_catch*catch_boat\n",
        "V_charter = ASC_charter + B_price*price_charter + B_catch*catch_charter\n",
        "\n",
        "V_base = {1: V_beach,\n",
        "     2: V_pier,\n",
        "     3: V_boat,\n",
        "     4: V_charter}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_J5poICol34Q"
      },
      "source": [
        "model_base, results_base = qbus_estimate_bgm(V_base, data_pd, 'mode', 'fish')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qu_aguema04"
      },
      "source": [
        "results_base.getEstimatedParameters()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mtMh3Bl6FW8"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "# Nested logit Question: Estimate the model \n",
        "Nested logit, we declare the nest parameter, the parameter that will represent the 'strength' of the nesting.\n",
        "\n",
        "We use the biogeme expression (same as for the Beta coefficients). In biogeme\n",
        "the larger the parameter, the stronger the nesting. Its minimum value should be 1, the maximum can be a large enough number such as 100. This comes from the $\\lambda$ in the theory part that is between 0 and 1, biogeme use a $\\mu = 1/ \\lambda$ so it should be a number larger than 1 if $\\lambda$ is between 0 and 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T202OKu26mTv"
      },
      "source": [
        "MU_nest_A = exp.Beta('MU_nest_A', 1, 1, 100, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ew8Okgp26mTv"
      },
      "source": [
        "And the nest structure. In biogeme, this is done via a python tuple of two elements:\n",
        "1. The first element is the the parameter\n",
        "2. The second parameter is a python list of ids of the alternatives that are affected by the grouping. **Remember to map the ids to the alternatives correctly!**\n",
        "\n",
        "In the following cell, we create a grouping for beach (alt. 1), pier (alt. 2) and private boat (alt. 3). This is the grouping that will be affected by the `MU_NONCHART`. Other group, in this case it is only formed by the charter boat.\n",
        "Since there is only one altenative in the group, we can set its grouping parameter to 1.\n",
        "Finaly we put all tuples together to create the full grouping specification that is passed to biogeme."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rBft98X6mTv"
      },
      "source": [
        "nest_A = MU_nest_A, [1, 2, 3]\n",
        "nest_B = 1.0, [4]\n",
        "nests_struct = nest_A, nest_B"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHQARKkD6mTv"
      },
      "source": [
        "Then we will estimate and check the model parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcGDdPhU6mTw"
      },
      "source": [
        "model_nest, results_nest = qbus_estimate_nested_bgm(V_base, data_pd, nests_struct, 'mode', 'data_nest' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfvP0WRn6mTw"
      },
      "source": [
        "The estimation of the model gives similar coefficients to the paper."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qhd3rYFi6mTw"
      },
      "source": [
        "results_nest.getEstimatedParameters()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bXGQXi-PyGD"
      },
      "source": [
        "To check is the nested model is a statistically significant improvement over the multinomial logit version, we can do a likelihood ratio test, as usual, when the complex model is nested. If the only thing that changes is the inclusion of the 'nesting parameter' we test if nesting is useful. We can check several modifications at once, but then we would not be able to sepearate the nesting part form the rest. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWajooN5Bsak"
      },
      "source": [
        "qbus_likeli_ratio_test_bgm(results_nest, results_base, 0.95)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g7XfTB8Y7Bmb"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "# Nested logit question: Find/Discuss the nest structure in the data\n",
        "\n",
        "Apart from knowing how to estimate the nested logit and interpret the results, we need to be able to compare different nesting structures that might be applicable to the data, to pick the one that is better. In practice, sometimes there are several 'reasonable' nesting structures ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ui2JR6OC_XZE"
      },
      "source": [
        "MU_nest_B = exp.Beta('MU_nest_B', 1, 1, 100, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arpkVrIv5_oQ"
      },
      "source": [
        "alt_nest_A = MU_nest_A, [1, 2, 4]\n",
        "alt_nest_B = MU_nest_B, [3]\n",
        "alt_nests_struct = alt_nest_A, alt_nest_B"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K48SJvek_iIW"
      },
      "source": [
        "alt_model_nest, alt_results_nest = qbus_estimate_nested_bgm(V_base, data_pd, alt_nests_struct, 'mode', 'data_nest' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9VwO7gBM_pPF"
      },
      "source": [
        "alt_results_nest.getEstimatedParameters()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhQPk9cbHJgh"
      },
      "source": [
        "What happens when comparing the nested logit is that we cannot always use the likelihood ratio test, because the models to compare are not always nested (one is not always is included in the other). When models are very similar, just differing on the nested structure and the same number of parameters, we can compare the likelihoods directly (the larger the better). This will not give us a nice p-value but it can help decide among nest structures.\n",
        "\n",
        "**However,** it more general if we just use the  Akaike information criteria directly (AIC). Remember that lower means a better model, and in practice is very conservative (adding parameter has to improve the model by 'a lot').."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtPvWq5GAMTi"
      },
      "source": [
        "#Likelihood ratio test is rarely applicable to compare between nests\n",
        "#qbus_likeli_ratio_test_bgm(alt_results_nest, results_nest, 0.95)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOq00EgYDi2K"
      },
      "source": [
        "#alt_results_nest.data.logLike"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kZBFRoODmDA"
      },
      "source": [
        "#results_nest.data.logLike"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GB-_HdejDf5U"
      },
      "source": [
        "We should go directly for the Akaike information criteria (the lower the better).."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azLWObWxB-uZ"
      },
      "source": [
        "alt_results_nest.data.akaike"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3fmvTrzCJIq"
      },
      "source": [
        "results_nest.data.akaike"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZtTosUCJXuu"
      },
      "source": [
        "The results from loglik and Akaike are consistent in this case"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7FYqaFCIoNa"
      },
      "source": [
        "results_base.data.akaike"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMbMnRLfVJJo"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "# Ordered Logit question: Estimate the model and interpretation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omPr8S9XVaDG"
      },
      "source": [
        "The ordered logit considers only one utility function, not one per alternative.\n",
        "The main 'challenge' in the ordered logit is realizing that the problem we are dealing with can be modeled with the ordered logit, that the alternatives have some sort of 'natural' order."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEAtiY0rWFti"
      },
      "source": [
        "ASC_ord = exp.Beta('ASC_ord', 0, None, None, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bf83xKaFWCKN"
      },
      "source": [
        "V_ord = ASC_ord + B_price*price_beach + B_catch*catch_beach + B_price*price_pier + B_catch*catch_pier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-A4gBIjnrx1"
      },
      "source": [
        "We use the auxiliary function `qbus_estimate_ordered_bgm`, notice the argument `[1,3,2,4]` specifying the desired order of the alternatives. In this case, it means we think that the order is:\n",
        "\n",
        " beach < private boat < pier < charterboat.\n",
        " \n",
        " **Please pay attention to the order that we specify! Otherwise we are incorrectly specify the model.**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqihL9PwjmFj"
      },
      "source": [
        "qord_model, qord_results = qbus_estimate_ordered_bgm(V_ord, [1,3,2,4], data_pd, 'mode', )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1tnWUQ5ks9h"
      },
      "source": [
        "qord_results.getEstimatedParameters()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNbxuEYn4Q_x"
      },
      "source": [
        "The interpretation of the coefficients is slightly different because there is only one utility, therefoe, positive numbers that increase utility make the alternatives later in our specific order more likely. The interpretation of the cutoff points tau1 would be the fist cutoff, then tau2 would be tau1+delta_2, tau3 = tau2 + delta_3 and so on. Given the expression of the logit, it is difficult to get some clear intuition on the differences here, it is better to look at the predicions/simuations directly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fABfvyZnXfy0"
      },
      "source": [
        "qbus_simulate_bgm(qord_model, qord_results.getBetaValues(), data_pd)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMIr-VivFLcd"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "# Ordered Logit question: Finding the order"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rNMC4bMyFSSr"
      },
      "source": [
        "The situation when several possible orders seem 'reasonable' we can compare them. It is a bit far-fetched, but it is also simple to test. We can use Akaike."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svlTSEm7FjjQ"
      },
      "source": [
        "qord_model_na, qord_results_na = qbus_estimate_ordered_bgm(V_ord, [2,4,3,1], data_pd, 'mode')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RoavYJm2Gt_r"
      },
      "source": [
        "qord_results_na.getGeneralStatistics()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9EhT_3uHTdw"
      },
      "source": [
        "We see the new order is better than the original, but both orders are really bad ideas..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWUD5E6xFzW2"
      },
      "source": [
        "qord_results_na.data.akaike"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPEpJXqfF4df"
      },
      "source": [
        "qord_results.data.akaike"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOXPOrMcF6Ts"
      },
      "source": [
        "results_base.data.akaike"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xojh_NlC5q4K"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "\n",
        "# Panel and mixed logit questions\n",
        "\n",
        "We do not have auxiliary functions for the mixed model (yet) so we have to estimate it manually. We will go back to the Swissmetro dataset because it shows a nice result."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szu60o6XIbWO"
      },
      "source": [
        "# Panel and mixed logit questions: Panel vs Nonpanel\n",
        "\n",
        "What happens when we include the panel information?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jD__NLr8LQwQ"
      },
      "source": [
        "Toggle `do_PANEL` and the Runtime -> Run After from here to check the differences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRZVLGPaJcB1"
      },
      "source": [
        "do_PANEL = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g9reskyw5tc_"
      },
      "source": [
        "\n",
        "data_pd = pd.read_csv('http://transp-or.epfl.ch/data/swissmetro.dat', sep='\\t')\n",
        "\n",
        "#data_pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVPiQ_-jIbqX"
      },
      "source": [
        "The basic cleanup of the Swissmetro dataset, remove invalid choices (0s in the CHOICE variable)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgKwm2N65v5X"
      },
      "source": [
        "data_pd = data_pd[ data_pd['CHOICE'] > 0]\n",
        "data_bgm = db.Database(\"swiss\", data_pd)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--4ijyk57j6-"
      },
      "source": [
        "globals().update(data_bgm.variables)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcPiXMUN6E61"
      },
      "source": [
        "if (do_PANEL):\n",
        " data_bgm.panel(\"ID\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7WXxOSCH6NTR"
      },
      "source": [
        "ASC_CAR = exp.Beta ( 'ASC_CAR' ,0, None , None ,0)\n",
        "ASC_TRAIN = exp.Beta ( 'ASC_TRAIN' ,0, None , None ,0)\n",
        "ASC_SM = exp.Beta ( 'ASC_SM' ,0, None , None ,1)\n",
        "B_TIME = exp.Beta ( 'B_TIME' ,0, None , None ,0)\n",
        "B_COST = exp.Beta ( 'B_COST' ,0, None , None ,0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdkAY4nb7L8s"
      },
      "source": [
        "V1 = ASC_TRAIN + B_TIME * TRAIN_TT + B_COST * TRAIN_CO \n",
        "V2 = ASC_SM + B_TIME * SM_TT + B_COST * SM_CO \n",
        "V3 = ASC_CAR + B_TIME * CAR_TT + B_COST * CAR_CO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvK71R587Oqa"
      },
      "source": [
        "V = {1: V1 ,\n",
        "2: V2 ,\n",
        "3: V3 }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PPe-B7Os7QcZ"
      },
      "source": [
        "av = {1: TRAIN_AV,\n",
        "2: SM_AV,\n",
        "3: CAR_AV }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orKX23f-7XPE"
      },
      "source": [
        "logprob = None\n",
        "if (do_PANEL):\n",
        "  obsprob = models.logit(V,av, CHOICE)\n",
        "  condprobIndiv = exp.PanelLikelihoodTrajectory(obsprob)\n",
        "  logprob = exp.log((condprobIndiv))\n",
        "else:\n",
        "  logprob = models.loglogit (V , av , CHOICE )\n",
        "\n",
        "bgm_model = bio.BIOGEME ( data_bgm, logprob )\n",
        "results = bgm_model.estimate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yjtQKutD8SpL"
      },
      "source": [
        "results.getEstimatedParameters()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrV4tm529IaI"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "# Mixed logit question: Estimation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7Hw5WBL9LQ3"
      },
      "source": [
        "SIGMA_B_COST = exp.Beta('SIGMA_B_COST',1,0,None,0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DBx826Lk9W62"
      },
      "source": [
        "EC_B_COST = SIGMA_B_COST * exp.bioDraws('EC_B_COST','NORMAL')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldGX-lTO9ca7"
      },
      "source": [
        "V1 = ASC_TRAIN + B_TIME * TRAIN_TT + (B_COST + EC_B_COST)  * TRAIN_CO \n",
        "V2 = ASC_SM + B_TIME * SM_TT + (B_COST + EC_B_COST) * SM_CO \n",
        "V3 = ASC_CAR + B_TIME * CAR_TT + (B_COST + EC_B_COST) * CAR_CO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8J92EHb_-U5t"
      },
      "source": [
        "V = {1: V1, 2:V2, 3:V3}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrU6ylTf98ff"
      },
      "source": [
        "obsprob = models.logit(V, av, CHOICE)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMrTTiT7uizv"
      },
      "source": [
        "if (do_PANEL):\n",
        " condprobIndiv = exp.PanelLikelihoodTrajectory(obsprob)\n",
        "else:\n",
        " condprobIndiv = obsprob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7vqM0O9YwVz"
      },
      "source": [
        "#condprobIndiv = exp.PanelLikelihoodTrajectory(obsprob)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfPNY5auywhh"
      },
      "source": [
        "And Step 2 we take the model and then modify it by the expresion `exp.MonteCarlo`. The final log it to take the loglikelihood."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PS69PxS9yAGG"
      },
      "source": [
        "logprob = exp.log(exp.MonteCarlo(condprobIndiv))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRtpFZRayEde"
      },
      "source": [
        "We  are using simulation,  so we have to tell biogeme how many draws from the distribution are we going to generate. The more draws, the more accurate estimation, but it is compuationally costly.\n",
        "\n",
        "We also set up a seed, so we can get the same results if the run the notebook again (setting up a seed is a good habit in general)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQ4kHXoaxoY8"
      },
      "source": [
        "\n",
        "# Create the Biogeme object\n",
        "biogeme  = bio.BIOGEME(data_bgm,logprob,numberOfDraws=50, seed=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQpnVVzO-CAM"
      },
      "source": [
        "results_mixed = biogeme.estimate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGdjIPQM-G9u"
      },
      "source": [
        "results_mixed.getEstimatedParameters()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2S7TvfbZ-mH1"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "# Mixed Logit question: Interpretation of the distribution of a parameter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jf69M46IAnC6"
      },
      "source": [
        "* The main interpretation is the understanding that parameters are 'random' so the output is an estimation of the probability distribution of the parameters, in this case COST follows a normal (approximately) $N(-0.0106, 0.020^2)$.\n",
        "\n",
        "* Secondary interpretations are doing 'something' with the distribution. \n",
        " For example: **What percentage of people in the population have a cost parameter that is positive?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2JfRHhTBYpn"
      },
      "source": [
        "from scipy.stats import norm\n",
        "\n",
        "1 - norm.cdf(0, results_mixed.getBetaValues()['B_COST'], results_mixed.getBetaValues()['SIGMA_B_COST'])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}